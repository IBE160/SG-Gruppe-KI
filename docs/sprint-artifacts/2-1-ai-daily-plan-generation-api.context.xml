<story-context id="2-1-ai-daily-plan-generation-api" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>1</storyId>
    <title>AI Daily Plan Generation API</title>
    <status>validated</status>
    <generatedAt>2025-12-10</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/2-1-ai-daily-plan-generation-api.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>user</asA>
    <iWant>the system to generate a personalized daily workout plan based on my current context and history</iWant>
    <soThat>I can receive an adaptive training recommendation from the AI</soThat>
    <tasks>
        -   [ ] **Task 1: Implement FastAPI Endpoint (AC2.1.1)**
            -   [ ] Subtask 1.1: Create a new endpoint `POST /plans/generate` in `apps/api`.
            -   [ ] Subtask 1.2: Define request (e.g., `context`) and response models for the endpoint using Pydantic.
        -   [ ] **Task 2: Integrate with OpenAI API (AC2.1.2)**
            -   [ ] Subtask 2.1: Develop `AI Orchestrator` service to construct a detailed prompt using user profile, goals, history, and current context.
            -   [ ] Subtask 2.2: Implement logic to call the OpenAI API with the constructed prompt.
            -   [ ] Subtask 2.3: Handle potential OpenAI API errors (e.g., timeout, invalid response).
            -   [ ] Subtask 2.4: Validate the AI's JSON response against a predefined schema.
        -   [ ] **Task 3: Store Generated Plan (AC2.1.3)**
            -   [ ] Subtask 3.1: Implement logic in `Plan Service` to store the generated workout plan (structured JSON) in the `WorkoutPlans` table.
            -   [ ] Subtask 3.2: Ensure the plan is linked to the `user_id` and `plan_date`.
        -   [ ] **Task 4: Include AI Explanation (AC2.1.4)**
            -   [ ] Subtask 4.1: Extract the `ai_explanation` from the AI's response.
            -   [ ] Subtask 4.2: Include the `ai_explanation` in the `POST /plans/generate` endpoint's response.
    </tasks>
  </story>

  <acceptanceCriteria>
    <criterion id="AC2.1.1">A `POST /plans/generate` endpoint is created in the FastAPI backend.</criterion>
    <criterion id="AC2.1.2">The endpoint constructs a prompt and successfully calls the OpenAI API to generate a workout plan in a structured JSON format.</criterion>
    <criterion id="AC2.1.3">The generated plan is stored in the `WorkoutPlans` table.</criterion>
    <criterion id="AC2.1.4">The endpoint includes an `ai_explanation` in the response if the plan was adapted based on user context.</criterion>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>Novel Architectural Patterns</section>
        <snippet>Pattern: Adaptive Workout Dialogue - describes the conversational loop between the user and the AI.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-2.md</path>
        <title>Epic Technical Specification: AI-Powered Training & Logging</title>
        <section>Story 2.1: AI Daily Plan Generation API</section>
        <snippet>Details of ACs and overview for Story 2.1.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-2.md</path>
        <title>Epic Technical Specification: AI-Powered Training & Logging</title>
        <section>Data Models and Contracts</section>
        <snippet>Specifies the `WorkoutPlans` table structure.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-2.md</path>
        <title>Epic Technical Specification: AI-Powered Training & Logging</title>
        <section>APIs and Interfaces</section>
        <snippet>Details the `POST /plans/generate` API endpoint request and response.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-2.md</path>
        <title>Epic Technical Specification: AI-Powered Training & Logging</title>
        <section>Workflows and Sequencing</section>
        <snippet>Describes the "AI Daily Plan Generation" workflow.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-2.md</path>
        <title>Epic Technical Specification: AI-Powered Training & Logging</title>
        <section>Test Strategy Summary</section>
        <snippet>Outlines testing for `AI Orchestrator` and `WorkoutPlans` table.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-2.md</path>
        <title>Epic Technical Specification: AI-Powered Training & Logging</title>
        <section>Non-Functional Requirements</section>
        <snippet>Covers AI Latency, Security (Prompt Injection), and Reliability (AI Service Failure).</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>apps/api/app/api/plans.py</path>
        <kind>api-endpoint</kind>
        <symbol>plans_router</symbol>
        <lines>N/A</lines>
        <reason>New file for API endpoints related to workout plans.</reason>
      </artifact>
      <artifact>
        <path>apps/api/app/services/ai_orchestrator.py</path>
        <kind>service</kind>
        <symbol>AIOrchestratorService</symbol>
        <lines>N/A</lines>
        <reason>New service to handle AI prompt construction and OpenAI API calls.</reason>
      </artifact>
      <artifact>
        <path>apps/api/app/services/plan_service.py</path>
        <kind>service</kind>
        <symbol>PlanService</symbol>
        <lines>N/A</lines>
        <reason>New service to manage CRUD operations for WorkoutPlans.</reason>
      </artifact>
      <artifact>
        <path>apps/api/app/models/workout_plan.py</path>
        <kind>data-model</kind>
        <symbol>WorkoutPlanModel</symbol>
        <lines>N/A</lines>
        <reason>New Pydantic models for representing workout plans.</reason>
      </artifact>
      <artifact>
        <path>apps/api/main.py</path>
        <kind>config</kind>
        <symbol>app</symbol>
        <lines>N/A</lines>
        <reason>Existing main FastAPI app file, needs to include new `plans` router.</reason>
      </artifact>
    </code>
    <dependencies>
      <ecosystem name="Python">
        <package name="fastapi" version="0.123.7" />
        <package name="pydantic" version="^2.x" />
        <package name="openai" version="^1.x" /> <!-- Assuming an OpenAI Python client library -->
        <package name="supabase-py" version="^2.x" />
      </ecosystem>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>Endpoint must be protected by JWT authentication.</constraint>
    <constraint>AI Orchestrator must handle prompt engineering and response validation.</constraint>
    <constraint>OpenAI API integration is external and must be handled gracefully for failures/timeouts.</constraint>
    <constraint>Data models must strictly adhere to `WorkoutPlans` table schema.</constraint>
    <constraint>Supabase RLS must ensure data segregation by `user_id`.</constraint>
  </constraints>
  <interfaces></interfaces>
  <tests>
    <standards>
      Integration tests for AI Orchestrator mocking OpenAI API calls.
      Integration tests for Plan Service validating database interactions.
      Unit tests for Pydantic models.
      Test files co-located where appropriate (`tests/api/` or `tests/services/`).
    </standards>
    <locations>
      <location>apps/api/tests/api/test_plans.py</location>
      <location>apps/api/tests/services/test_ai_orchestrator.py</location>
      <location>apps/api/tests/models/test_workout_plan.py</location>
    </locations>
    <ideas>
      <idea>Test `POST /plans/generate` endpoint with valid context, mock OpenAI response, and verify `WorkoutPlans` table update.</idea>
      <idea>Test `POST /plans/generate` endpoint with invalid context to verify validation errors.</idea>
      <idea>Test AI Orchestrator's prompt construction logic with various user profiles and contexts.</idea>
      <idea>Test AI Orchestrator's response parsing and validation for both valid and malformed AI responses.</idea>
      <idea>Test Plan Service's ability to store and retrieve workout plans from the database.</idea>
      <idea>Test endpoint's error handling for OpenAI API failures (e.g., mock connection error, timeout).</idea>
    </ideas>
  </tests>
</story-context>